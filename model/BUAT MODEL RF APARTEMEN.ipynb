{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT PACKAGE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT DATA\n",
    "df = pd.read_excel(\"persatuan data berharga 2.xlsx\")\n",
    "predictors = ['Kecamatan','BR', 'Luas', 'Fasilitas','Lantai','Unit']\n",
    "label = 'Harga'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2875 entries, 0 to 2874\n",
      "Data columns (total 7 columns):\n",
      "Kecamatan    2875 non-null object\n",
      "BR           2875 non-null int64\n",
      "Luas         2875 non-null float64\n",
      "Fasilitas    2875 non-null object\n",
      "Lantai       2875 non-null object\n",
      "Unit         2875 non-null object\n",
      "Harga        2875 non-null int64\n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 157.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#MENAMPILKAN INFO DATAFRAME\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LABEL ENCODER\n",
    "le = dict()\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == np.object:\n",
    "        le[column] = LabelEncoder()\n",
    "        df[column] = le[column].fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2875 entries, 0 to 2874\n",
      "Data columns (total 7 columns):\n",
      "Kecamatan    2875 non-null int64\n",
      "BR           2875 non-null int64\n",
      "Luas         2875 non-null float64\n",
      "Fasilitas    2875 non-null int64\n",
      "Lantai       2875 non-null int64\n",
      "Unit         2875 non-null int64\n",
      "Harga        2875 non-null int64\n",
      "dtypes: float64(1), int64(6)\n",
      "memory usage: 157.3 KB\n"
     ]
    }
   ],
   "source": [
    "#INFO DATAFRAME\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MEMBAGI DATA TRAIN DAN TEST\n",
    "df_train, df_test, y_train, y_test = train_test_split(df[predictors], df[label], test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MEMBUAT MODEL TRAIN DEFAULT\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X=df_train, y=y_train)# Train the model on training data\n",
    "y_predtrain = model.predict(X=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the absolute errors train\n",
    "errorstrain = abs(y_predtrain - y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 682831.2 degrees.\n"
     ]
    }
   ],
   "source": [
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errorstrain), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mapetrain = 100 * (errorstrain / y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.49 %.\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display accuracy\n",
    "accuracytrain = 100 - np.mean(mapetrain)\n",
    "print('Accuracy:', round(accuracytrain, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MEMBUAT MODEL TEST\n",
    "y_predtest = model.predict(X=df_test)# Use the forest's predict method on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the absolute errors test\n",
    "errorstest = abs(y_predtest - y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1059248.07 degrees.\n"
     ]
    }
   ],
   "source": [
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errorstest), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mapetest = 100 * (errorstest / y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.94 %.\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display accuracy\n",
    "accuracytest = 100 - np.mean(mapetest)\n",
    "print('Accuracy:', round(accuracytest, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(model, 'model.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kecamatan</th>\n",
       "      <th>BR</th>\n",
       "      <th>Luas</th>\n",
       "      <th>Fasilitas</th>\n",
       "      <th>Lantai</th>\n",
       "      <th>Unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Kecamatan  BR  Luas  Fasilitas  Lantai  Unit\n",
       "729          5   2  34.0          0       2     0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = json.dumps({'Kecamatan':5, 'BR':2, 'Luas':34, 'Fasilitas':0, 'Lantai':2, 'Unit':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([5, 2, 34, 0, 2, 0]).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  2, 34,  0,  2,  0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4955813.683091934"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4955813.683091934"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Kecamatan':5, 'BR':2, 'Luas':34, 'Fasilitas':0, 'Lantai':2, 'Unit':0}\n",
    "predict_request = [data['Kecamatan'], data['BR'], data['Luas'], data['Fasilitas'], data['Lantai'], data['Unit']]\n",
    "predict_request = np.array(predict_request).reshape(1, -1)\n",
    "     # predict_request = np.array(predict_request)\n",
    "     # # query = pd.DataFrame(json_)\n",
    "     # # query = pd.get_dummies(query_df)\n",
    "prediction = model.predict(predict_request)\n",
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_features': [3],\n",
    "    'n_estimators': [100, 200, 300, 1000, 1500]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 10, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 300 candidates, totalling 3000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   24.0s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed: 16.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed: 29.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1977 tasks      | elapsed: 37.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 47.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3000 out of 3000 | elapsed: 54.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 90,\n",
       " 'max_features': 3,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 8,\n",
       " 'n_estimators': 300}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(X=df_train, y=y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVALUATE THE BEST MODEL SEARCH GRID TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X=df_train, y=y_train):\n",
    "    predictions = model.predict(X=df_train)\n",
    "    errors = abs(predictions - y_train)\n",
    "    mape = 100 * np.mean(errors / y_train)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 682831.2026 degrees.\n",
      "Accuracy = 89.49%.\n"
     ]
    }
   ],
   "source": [
    "base_model = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "base_model.fit(X=df_train, y=y_train)\n",
    "base_accuracy = evaluate(base_model, X=df_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 874829.7254 degrees.\n",
      "Accuracy = 86.46%.\n"
     ]
    }
   ],
   "source": [
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate(best_grid, X=df_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement of -3.39%.\n"
     ]
    }
   ],
   "source": [
    "print('Improvement of {:0.2f}%.'.format( 100 * (grid_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVALUATE THE BEST MODEL SEARCH GRID TESTING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluatetest(model, X=df_test, y=y_test):\n",
    "    predictionstest = model.predict(X=df_test)\n",
    "    errorstest = abs(predictionstest - y_test)\n",
    "    mapetest = 100 * np.mean(errorstest / y_test)\n",
    "    accuracytest = 100 - mapetest\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errorstest)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracytest))\n",
    "    \n",
    "    return accuracytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 568424.3797 degrees.\n",
      "Accuracy = 91.31%.\n"
     ]
    }
   ],
   "source": [
    "base_model = RandomForestRegressor(random_state = 42)\n",
    "base_model.fit(X=df_test, y=y_test)\n",
    "base_accuracy = evaluatetest(base_model, X=df_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 1155466.6997 degrees.\n",
      "Accuracy = 81.69%.\n"
     ]
    }
   ],
   "source": [
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate(best_grid, X=df_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
